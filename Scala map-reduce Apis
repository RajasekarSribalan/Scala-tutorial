We can use Map Reduce paradigm while processing data in collections

Row level transformations – map
Filtering data – filter
Aggregating data – reduce, fold
and many more


Problem Statement

1.Create a list of numbers ,say 1 to 100
2.Get Sum of squares of all even numbers (Row level transformation - map and then aggregation)
  Filter -> Even number (Row level transformation)
  Filter -> Squares each number (Row level tranformation)
  Aggregation -> Sum of all


*** Note : ALways do the filer and then do the other row level tranformation.Because it effective

scala> 1 to 100
res25: scala.collection.immutable.Range.Inclusive = Range(1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100)

scala> val list = (1 to 100).toList
list: List[Int] = List(1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100)

scala> // Get Sum of all even numbers

scala> // Get Sum of squares all even numbers

scala> val filtered = list.filter
filter   filterNot

scala> val filtered = list.filter
   def filter(p: A => Boolean): Repr

scala> val filtered = list.filter
   def filter(p: A => Boolean): Repr

scala> val filtered = list.filter(eachElement => eachElement % 2 == 0)
filtered: List[Int] = List(2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 22, 24, 26, 28, 30, 32, 34, 36, 38, 40, 42, 44, 46, 48, 50, 52, 54, 56, 58, 60, 62, 64, 66, 68, 70, 72, 74, 76, 78, 80, 82, 84, 86, 88, 90, 92, 94, 96, 98, 100)

scala> val map = filtered.map
map   mapConserve

scala> val map = filtered.map

def map[B, That](f: A => B)(implicit bf: generic.CanBuildFrom[List[A],B,That]): That

scala> val map = filtered.map(record => record * record)
map: List[Int] = List(4, 16, 36, 64, 100, 144, 196, 256, 324, 400, 484, 576, 676, 784, 900, 1024, 1156, 1296, 1444, 1600, 1764, 1936, 2116, 2304, 2500, 2704, 2916, 3136, 3364, 3600, 3844, 4096, 4356, 4624, 4900, 5184, 5476, 5776, 6084, 6400, 6724, 7056, 7396, 7744, 8100, 8464, 8836, 9216, 9604, 10000)

scala> //Conventional approach

scala> var total = 0
total: Int = 0

scala> for(element <- map) total =  total + element

scala> total
res27: Int = 171700

scala> //Functional approach

scala> 

scala> val reducedOutput = map.reduce
reduce       reduceLeftOption   reduceRight            
reduceLeft   reduceOption       reduceRightOption      

scala> val reducedOutput = map.reduce
   def reduce[A1 >: A](op: (A1, A1) => A1): A1

scala> val reducedOutput = map.reduce
   def reduce[A1 >: A](op: (A1, A1) => A1): A1

scala> val reducedOutput = map.reduce((total,element) => total+element)
reducedOutput: Int = 171700

scala> val reducedOutput = map.reduce((sum,element) => sum+element)
reducedOutput: Int = 171700

scala> //Rich collections

scala> 

scala> 

scala> filtered.sum
res28: Int = 2550

scala> map.sum
res29: Int = 171700

scala> //sort

scala> list.
++              flatten              minBy               sortWith        
++:             fold                 mkString            sorted          
+:              foldLeft             nonEmpty            span            
/:              foldRight            orElse              splitAt         
:+              forall               padTo               startsWith      
::              foreach              par                 stringPrefix    
:::             genericBuilder       partition           sum             
:\              groupBy              patch               tail            
addString       grouped              permutations        tails           
aggregate       hasDefiniteSize      prefixLength        take            
andThen         head                 product             takeRight       
apply           headOption           productArity        takeWhile       
applyOrElse     indexOf              productElement      to              
asInstanceOf    indexOfSlice         productIterator     toArray         
canEqual        indexWhere           productPrefix       toBuffer        
collect         indices              reduce              toIndexedSeq    
collectFirst    init                 reduceLeft          toIterable      
combinations    inits                reduceLeftOption    toIterator      
companion       intersect            reduceOption        toList          
compose         isDefinedAt          reduceRight         toMap           
contains        isEmpty              reduceRightOption   toSeq           
containsSlice   isInstanceOf         repr                toSet           
copyToArray     isTraversableAgain   reverse             toStream        
copyToBuffer    iterator             reverseIterator     toString        
corresponds     last                 reverseMap          toTraversable   
count           lastIndexOf          reverse_:::         toVector        
diff            lastIndexOfSlice     runWith             transpose       
distinct        lastIndexWhere       sameElements        union           
drop            lastOption           scan                unzip           
dropRight       length               scanLeft            unzip3          
dropWhile       lengthCompare        scanRight           updated         
endsWith        lift                 segmentLength       view            
exists          map                  seq                 withFilter      
filter          mapConserve          size                zip             
filterNot       max                  slice               zipAll          
find            maxBy                sliding             zipWithIndex    
flatMap         min                  sortBy                              

scala> list.sort
sortBy   sortWith   sorted

scala> list.sort
<console>:9: error: value sort is not a member of List[Int]
              list.sort
                   ^

scala> list.sort
sortBy   sortWith   sorted

scala> list.sort
sortBy   sortWith   sorted

scala> list.sorted
res31: List[Int] = List(1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100)

scala> val reducedOutput2 = map.reduce(_ + _)
reducedOutput2: Int = 171700



******* I/O Operations and Tuples

Performing I/O Operations
Scala provide few APIs to read data from files. If you want to understand File I/O in detail you can start exploring Java APIs and use as part of Scala programming. Let us see steps involved in reading data into a collection.

import scala.io.Source
Use Source.fromFile to read data into memory as character array/buffered source
Use getLines to use new line character as delimiter and create collections
We read data from order_items for demonstration purpose into a variable called orderItems
Using map reduce APIs

Get all order items for order id 2 – use filter API
Extract order item subtotal for each of the item belonging to order id 2 – use map API
Add order item subtotal to get revenue for order id 2 – use reduce API



Setting up datasets

git clone https://github.com/dgadiraju/data.git


this clone repo will have all required dataset.

The data is in the form of ,

1,1,957,1,299.98,299.98
order_item,order_item_order_id,order_item_product_id,quantity,product_price

# BY deafult buffered reader will reach each character. So we wil get the output like this.

scala> import scala.io.
AnsiColor        Codec                       Position   StdIn   
BufferedSource   LowPriorityCodecImplicits   Source             

scala> import scala.io.Source.
DefaultBufSize         fromChar          fromIterable   fromURL        
asInstanceOf           fromChars         fromRawBytes   isInstanceOf   
createBufferedSource   fromFile          fromString     stdin          
fromBytes              fromInputStream   fromURI        toString       

scala> import scala.io.Source
import scala.io.Source

scala> var orderItems = Source.fromFile("/home/raj/Project/itversity_data/data/retail_db/order_items/part-00000")
orderItems: scala.io.BufferedSource = non-empty iterator

scala> orderItems.take(10)
res32: Iterator[Char] = non-empty iterator

scala> orderItems.take(10).foreach(println)
1
,
1
,
9
5
7
,
1
,

scala> orderItems.take(20).foreach(println)
2
9
9
.
9
8
,
2
9
9
.
9
8


2
,
2
,
1
0


#### We have getLines operation which will give us each line



scala> import scala.io.Source
import scala.io.Source

scala> 

scala> 

scala> val orderItems = Source.fromFile("/home/hduser/itversity_data/data/retail_db/order_items/part-00000").getLines
orderItems: Iterator[String] = non-empty iterator

scala> val orderItemsFilter = orderItems.filter(orderItem =>orderItem.split(",")(1).toInt == 2)
orderItemsFilter: Iterator[String] = non-empty iterator

scala> val orderItemsMap = orderItemsFilter.map(orderItem => orderItem.split(",")(4).toFloat)
orderItemsMap: Iterator[Float] = non-empty iterator

scala> orderItemsMap.reduce((total,element) => total + element)
res6: Float = 579.98



--- We can use underscore in filter ,map and reduce--- e.g.,


scala> import scala.io.Source
import scala.io.Source

scala> val orderItems = Source.fromFile("/home/hduser/itversity_data/data/retail_db/order_items/part-00000").getLines.toList
orderItems: List[String] = List(1,1,957,1,299.98,299.98, 2,2,1073,1,199.99,199.99, 3,2,502,5,250.0,50.0, 4,2,403,1,129.99,129.99, 5,4,897,2,49.98,24.99, 6,4,365,5,299.95,59.99, 7,4,502,3,150.0,50.0, 8,4,1014,4,199.92,49.98, 9,5,957,1,299.98,299.98, 10,5,365,5,299.95,59.99, 11,5,1014,2,99.96,49.98, 12,5,957,1,299.98,299.98, 13,5,403,1,129.99,129.99, 14,7,1073,1,199.99,199.99, 15,7,957,1,299.98,299.98, 16,7,926,5,79.95,15.99, 17,8,365,3,179.97,59.99, 18,8,365,5,299.95,59.99, 19,8,1014,4,199.92,49.98, 20,8,502,1,50.0,50.0, 21,9,191,2,199.98,99.99, 22,9,1073,1,199.99,199.99, 23,9,1073,1,199.99,199.99, 24,10,1073,1,199.99,199.99, 25,10,1014,2,99.96,49.98, 26,10,403,1,129.99,129.99, 27,10,917,1,21.99,21.99, 28,10,1073,1,199.99,199.99, 29,11,365,1,59.99,59.99, 30,11,627,4,159.96,39.99, 31,11,1...
scala> 

scala> 

scala> val orderItemsFilter = orderItems.filter(_.split(",")(1).toInt == 2)
orderItemsFilter: List[String] = List(2,2,1073,1,199.99,199.99, 3,2,502,5,250.0,50.0, 4,2,403,1,129.99,129.99)

scala> val orderItemsMap = orderItemsFilter.map(_.split(",")(4).toFloat)
orderItemsMap: List[Float] = List(199.99, 250.0, 129.99)

scala> orderItemsMap.reduce(_ + _)
res8: Float = 579.98


***********


Understanding Tuples
Tuple is yet another powerful structure which is being used in many modern programming languages.
It is generic object where no name is associated with it.
It is generic object type, where attributes can be accessed using index (underscore notation)
Tuple represents a record with elements of heterogeneous type
It eliminates creating classes and then instantiating objects referring to class variables.
Knowledge of tuples is very important to get into Spark later.



scala> val tuple = (1,1,957,1,299.98,299.98)
tuple: (Int, Int, Int, Int, Double, Double) = (1,1,957,1,299.98,299.98)

scala> tuple.
_1   _3   _5   asInstanceOf   copy           productArity     productIterator   toString   
_2   _4   _6   canEqual       isInstanceOf   productElement   productPrefix                

scala> tuple.
_1   _3   _5   asInstanceOf   copy           productArity     productIterator   toString   
_2   _4   _6   canEqual       isInstanceOf   productElement   productPrefix                

scala> tuple._1
res9: Int = 1

scala> tuple._4
res10: Int = 1

scala> tuple._5
res11: Double = 299.98

scala> t(0)
<console>:11: error: not found: value t
              t(0)
              ^

scala> print(t)
<console>:11: error: not found: value t
              print(t)
                    ^

scala> tuple(0)
<console>:12: error: (Int, Int, Int, Int, Double, Double) does not take parameters
              tuple(0)
                   ^

scala> print(tuple)


